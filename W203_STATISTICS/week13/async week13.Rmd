---
title: "asyncweek13"
author: "K Iwasaki"
date: "August 9, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/K/Desktop/Berkeley/00_Academics/W203 STATS/week13")
library(car)
library(lmtest)
library(sandwich)

#closeAllConnections()
#rm(list=ls())

```

```{r}
load("mlb1.rdata")
ls()
desc

summary(data)

# examine the salary variable
summary(data$salary)
hist(data$salary, breaks = 200)

# this is a highly skewed distribution with a notable spike at
# the minimum volume
# check out a few of the smallest values of salary
head(sort(data$salary), 50)

# it turns out that the minimum mlb salary, set by negotiations
# with the MLB players association was $109,000 in 1993.
# this corresponds to the minimum value we see.

# we can also examine the log of salary
hist(log10(data$salary), breaks = 100)
hist(log(data$salary), breaks = 100)
# interestingly, the distribution is not very normal and looks
# almost uniform.

# examine years and games per year variables
summary(data$years)
hist(data$years, breaks = 20)
summary(data$gamesyr)
hist(data$gamesyr, breaks = 100)

hist(data$bavg, breaks = 100)
data[data$bavg > 400,]

summary(data$atbats)

head(sort(data$atbats), 50)

data[data$bavg < 150, ]

# we could fit a much more complicated model to account for this effect,
# but that's beyond the scope of this course
# a simpler idea is to mitigate the problem by removing players who have few chances to bat.
# To be eligible for the MLB batting title, players must have at least 3.1 at bats
# per game originally schedule, or approximately 500 at bats
# our dataset has 73 players with less than 500 at bats
sum(data$atbats<500)

# We proceed without these players,
mlb = data[data$atbats>=500,]
summary(mlb)
nrow(mlb)
# we are left with 280 players

summary(mlb$hrunsyr, breaks = 100)
hist(mlb$hrunsyr, breaks = 100)
summary(mlb$rbisyr, breaks = 100)
hist(mlb$rbisyr, breaks = 100)


model1 = lm(log(salary) ~ years + gamesyr + bavg + hrunsyr + rbisyr, data = mlb)
plot(model1)

# CLM Zero conditional mean --- looks ok,
# CLM hemokedasticity -- might be violated
# CLM normality (Q-Q plot) --- looks ok and given large sample size it is ok
# residuals vs. leverage ---there is no point that has high influence
# take-away --- heteroskedasticity

# robust standard error
coeftest(model1, vcov = vcovHC)



```

```{r}

# We could recreate the output in Wooldridge by putting in the full data
# including players with few at bats
model_wooldridge = lm(log(salary)~ years + gamesyr + bavg + hrunsyr + rbisyr, data = data)
plot(model_wooldridge)

# notice the outlying points in the residuals vs leverage plot with high leverage.
# These have small residuals, however, meaning that they don't affect our coefficients very much.
# In particular, a general rule is that a cook's distance of 1 represents a worrysome
# amount of influcence, and none of our datapoints are close.

coeftest(model_wooldridge, vcov = vcovHC)
# here, the extra variation in bavg is acting like measurement error
# thus, it is little suprise that we lose statistical significance,
# even though we're adding more data

```

```{r}
### Joint hypothesis testing
# we want to test whether the threee perfornce indicators are jointly significant.
# that is, whether the coefficients for bavg, hrunsyr, and rbisyr are all zero

# our restricted model is formed by removing the performance indicators
model_rest = lm(log(salary)~ years + gamesyr, data = mlb)
coeftest(model_rest, vcov = vcovHC)

# to test whether the difference in fit is significant, we use the wald test,
# which generalizes the usual F-test of overall significance,
# but allows for a heteroskedasticity-robust covariance matrix

waldtest(model1, model_rest, vcov = vcovHC)

# another useful command:
linearHypothesis(model1, c("bavg = 0", "hrunsyr = 0", "rbisyr = 0"), vcov = vcovHC)

# in this case, the three performance indicators are jointly significant.
# there is probably a great deal of multicollinearity, which explains
# why in woodridge's specification, none of their coefficients is individually significant.

```

```{r}
### tsting whether coeffcicients are different
# one question is whether a hit and a walk affect salary by the same amount.
# we write an alternate specification as follows:
model2 = lm(log(salary) ~ years + gamesyr + hits + bb, data = mlb)
coeftest(model2, vcov = vcovHC)

# our hypothesis is that the coefficients for hits and bb (walks) are the same
# we can test this manually by creating a new variable to equal the total

mlb$hits_plus_walks = mlb$hits + mlb$bb

model3 = lm(log(salary) ~ years + gamesyr + hits + hits_plus_walks, data = mlb)
coeftest(model3, vcov = vcovHC)

# in an even clearer way
linearHypothesis(model2, "hits = bb", vcov = vcovHC)

```


























